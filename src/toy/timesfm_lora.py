###########################################################################################################
# import libraries
###########################################################################################################

import time
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from peft import LoraConfig, get_peft_model
from timesfm import TimesFM_2p5_200M_torch, ForecastConfig
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from config import * # DATA, DATA_PATH, TIMESFM_HYPERPARAMS ë“± í¬í•¨

###########################################################################################################
# set user-defined functions
###########################################################################################################

def sliding_window_forecast(model_obj, data, context_len, horizon_len):
    predictions = []
    actuals = []
    
    # TimesFM ê³ ìˆ˜ì¤€ APIëŠ” inputs ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë‚´ë¶€ì ìœ¼ë¡œ íŒ¨ë”©/ë§ˆìŠ¤í¬ë¥¼ ìë™ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # ìˆ˜ë™ìœ¼ë¡œ ë§ˆìŠ¤í¬ë¥¼ ë„£ìœ¼ë©´ íŒ¨ì¹˜ í¬ê¸° ë¶ˆì¼ì¹˜ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ APIì— ë§¡ê¹ë‹ˆë‹¤.
    for i in range(0, len(data) - horizon_len + 1, horizon_len):
        start_idx = max(0, i - context_len)
        context_raw = data[start_idx : i]
        actual = data[i : i + horizon_len]
        
        # ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ëŠ” ì´ˆê¸° ì‹œì  ëŒ€ì‘
        if len(context_raw) == 0:
            context_input = [np.zeros(1, dtype=np.float32)]
        else:
            context_input = [context_raw.astype(np.float32)]

        # forecast()ëŠ” masks ì¸ìë¥¼ ì§ì ‘ ë°›ì§€ ì•Šìœ¼ë©° ë‚´ë¶€ì—ì„œ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
        forecast_output, _ = model_obj.forecast(
            horizon=horizon_len, 
            inputs=context_input
        )
        
        predictions.extend(forecast_output[0])
        actuals.extend(actual)
        
    return np.array(predictions), np.array(actuals)

def calculate_metrics(actual, pred):
    mae = np.mean(np.abs(actual - pred))
    mse = np.mean((actual - pred)**2)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((actual - pred) / (actual + 1e-9))) * 100
    return mae, mse, rmse, mape

###########################################################################################################
# set device and load data
###########################################################################################################

device = "cuda" if torch.cuda.is_available() else "cpu"

df_path = DATA_PATH[DATA]
tgt_col = DATASET[DATA]['target_col']
df_raw  = pd.read_csv(df_path)

target = df_raw[tgt_col].values.astype(np.float32)
ft_len = int(len(target) * 0.7)

tr_data = target[:ft_len] 
te_data = target[ft_len:] 

###########################################################################################################
# run TimesFM (Base Model)
###########################################################################################################

max_context = TIMESFM_HYPERPARAMS[DATA]['max_context']
max_horizon = TIMESFM_HYPERPARAMS[DATA]['max_horizon']

print(f"Loading Base TimesFM 2.5 on {device}...")
tmfm_base = TimesFM_2p5_200M_torch.from_pretrained(MODEL_VER)
tmfm_config = ForecastConfig(
    max_context=max_context, 
    max_horizon=max_horizon, 
    use_continuous_quantile_head=True, 
    normalize_inputs=True
)
tmfm_base.compile(tmfm_config)
tmfm_base.model.to(device)

if PIPELINE.get('TimesFM', True):
    print("ğŸš€ Predicting with TimesFM (Base)...")
    start_inf_base = time.time()
    base_preds, base_actuals = sliding_window_forecast(
        model_obj=tmfm_base, 
        data=te_data, 
        context_len=max_context, 
        horizon_len=max_horizon
    )
    print(f"Base Model Inference Time: {time.time() - start_inf_base:.2f}s")

    # ê²°ê³¼ ì¸ë±ìŠ¤ ê³„ì‚°
    start_idx = ft_len 
    pred_idx  = np.arange(start_idx, start_idx + len(base_preds))

###########################################################################################################
# run TimesFM + LoRA
###########################################################################################################

if PIPELINE.get('TimesFM_LoRA', True): 
    lora_param = LORA_HYPERPARAMS[DATA]
    epochs     = lora_param['epoch']

    # 1. LoRA ì„¤ì • ë° ì ìš©
    lora_config = LoraConfig(
        r               = lora_param['r'],
        lora_alpha      = lora_param['lora_alpha'],
        target_modules  = lora_param['target_modules'], 
        lora_dropout    = lora_param['lora_dropout'],
        bias            = lora_param['bias']
    )

    print(f"ğŸš€ Applying LoRA to TimesFM 2.5...")
    tmfm_lora_model = get_peft_model(tmfm_base.model, lora_config)
    tmfm_lora_model.print_trainable_parameters()

    # 2. í•™ìŠµìš© ë°ì´í„°ì…‹ (ê³ ì • ê¸¸ì´ íŒ¨ë”© ì‚¬ìš©)
    class TimeSeriesDataset(Dataset):
        def __init__(self, data, context_len, horizon_len):
            self.data = data
            self.cl = context_len
            self.hl = horizon_len
        def __len__(self):
            return len(self.data) - self.hl + 1
        def __getitem__(self, idx):
            start_idx = max(0, idx - self.cl)
            x_raw = self.data[start_idx : idx]
            y_raw = self.data[idx : idx + self.hl]
            
            x = np.zeros(self.cl, dtype=np.float32)
            mask = np.zeros(self.cl, dtype=np.float32)
            if len(x_raw) > 0:
                x[-len(x_raw):] = x_raw
                mask[-len(x_raw):] = 1.0
                
            return (torch.tensor(x).unsqueeze(-1), 
                    torch.tensor(y_raw).unsqueeze(-1), 
                    torch.tensor(mask).unsqueeze(-1))

    # [Tip] max_contextê°€ 64ì˜ ë°°ìˆ˜ì¼ ë•Œ ëª¨ë¸ í–‰ë ¬ ì—°ì‚°ì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
    train_ds = TimeSeriesDataset(tr_data, max_context, max_horizon)
    train_loader = DataLoader(train_ds, batch_size=lora_param.get('batch_size', 32), shuffle=True)

    # 3. Fine-tuning ì‹¤í–‰
    optimizer = optim.AdamW(tmfm_lora_model.parameters(), lr=lora_param.get('lr', 1e-4))
    criterion = nn.MSELoss()
    
    # TimesFM 2.5ì˜ íŒ¨ì¹˜ ì‚¬ì´ì¦ˆ ì •ì˜ (ë³´í†µ 64)
    PATCH_SIZE = 64 

    tmfm_lora_model.train()
    print(f"âŒ› Starting Fine-tuning for {epochs} epochs...")
    for epoch in range(epochs):
        total_loss = 0
        for x_batch, y_batch, mask_batch in train_loader:
            x_batch, y_batch, mask_batch = x_batch.to(device), y_batch.to(device), mask_batch.to(device)
            
            # [ìˆ˜ì • í¬ì¸íŠ¸] íŒ¨ì¹˜ êµ¬ì¡°ì— ë§ê²Œ ì°¨ì› ì¬êµ¬ì„± (Reshape)
            # (Batch, Seq_len, 1) -> (Batch, Num_patches, Patch_size)
            # ì˜ˆ: (32, 192, 1) -> (32, 3, 64)
            num_patches = x_batch.shape[1] // PATCH_SIZE
            
            x_patched = x_batch.view(x_batch.shape[0], num_patches, PATCH_SIZE)
            mask_patched = mask_batch.view(mask_batch.shape[0], num_patches, PATCH_SIZE)
            
            optimizer.zero_grad()
            
            # ëª¨ë¸ í˜¸ì¶œ (íŒ¨ì¹˜ëœ ë°ì´í„° ì „ë‹¬)
            # ì£¼ì˜: ëª¨ë¸ êµ¬í˜„ì— ë”°ë¼ inputs/masks ì¸ì ëŒ€ì‹  ì§ì ‘ ì „ë‹¬í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ
            outputs = tmfm_lora_model(inputs=x_patched, masks=mask_patched) 
            
            # ì†ì‹¤ ê³„ì‚° (ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì› ì¼ì¹˜ í™•ì¸)
            loss = criterion(outputs[0][:, :max_horizon, :], y_batch) 
            
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(train_loader):.6f}")

    # 4. LoRA ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    print("ğŸš€ Predicting with TimesFM + LoRA...")
    tmfm_lora_model.eval()
    tmfm_base.model = tmfm_lora_model # ë˜í¼ ë‚´ë¶€ ëª¨ë¸ êµì²´
    
    start_inf_lora = time.time()
    lora_preds, lora_actuals = sliding_window_forecast(
        model_obj=tmfm_base, 
        data=te_data, 
        context_len=max_context, 
        horizon_len=max_horizon
    )
    print(f"LoRA Model Inference Time: {time.time() - start_inf_lora:.2f}s")

    # 5. ì‹œê°í™” ë° ë¹„êµ
    plt.figure(figsize=(15, 7))
    plt.plot(target, label="Actual", color='black', alpha=0.3)
    if PIPELINE.get('TimesFM', True):
        plt.plot(pred_idx, base_preds, label="Base TimesFM", color='red', linestyle='--', alpha=0.7)
    plt.plot(pred_idx, lora_preds, label="TimesFM + LoRA", color='green', linewidth=1.5)
    
    plt.axvline(x=ft_len, color='blue', linestyle=':', label='Test Set Start')
    plt.title(f"Comparison: Base vs LoRA on {DATA}")
    plt.legend()
    plt.grid(True, alpha=0.2)
    plt.savefig(RES_PATH['plot']['timesfm_base_plot'].replace('base', 'lora_comp'), dpi=300)
    print(f"âœ… Comparison plot saved.")

    # 6. ê°€ì¤‘ì¹˜ ë¶„ì„
    print("\nğŸ” LoRA Weight Analysis (Norm):")
    for name, param in tmfm_lora_model.named_parameters():
        if 'lora_A' in name:
            print(f"  - {name:50} | Norm: {torch.norm(param).item():.6f}")